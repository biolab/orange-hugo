<html><head><title>Orange Data Mining - Orange Fairness - Equal Odds Postprocessing</title><meta property="og:title" content="Orange Fairness - Equal Odds Postprocessing"><meta property="og:description" content="Explore the Equal Odds Postprocessing widget in Orange, designed to fine-tune your model's fairness. We explain how the algorithm operates and showcase its effectiveness with an example using the German credit dataset."><meta property="og:image" content="/blog_img/2023/2023-09-19-fairness-equal-odds-postprocessing.png"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Orange Data Mining Toolbox"><meta name=author content="Bioinformatics Laboratory, University of Ljubljana"><meta name=google-site-verification content="DS7GH5M7ABi78pIC2rMcTBFx-UeBFObXOeLvR7Ow3EQ"><link rel="shortcut icon" href=/images/favicon.ico><link href='https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic' rel=stylesheet type=text/css><link href='https://fonts.googleapis.com/css?family=Covered+By+Your+Grace' rel=stylesheet type=text/css><link rel=stylesheet href=/plugins/bootstrap/css/bootstrap.min.css><link rel=stylesheet href=/plugins/font-awesome/css/font-awesome.css><link rel=stylesheet href=/plugins/lightgallery/css/lightgallery.css><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css rel=stylesheet><link rel=stylesheet href=/scss/main.58e8531e166454b3665e4c7132aa2f1762a5569c179efa4bbf56b266ce93bfac.css><script id=dsq-count-scr src=//orange-4.disqus.com/count.js async></script><noscript><style>.jsonly{display:none!important}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-J6PJZF75EX"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-J6PJZF75EX",{anonymize_ip:!1})}</script><script type=text/javascript src=/plugins/jquery-1.10.2.min.js></script>
<script type=text/javascript src=/plugins/jquery.form.js></script>
<script type=text/javascript src=/plugins/bootstrap/js/bootstrap.min.js></script>
<script type=text/javascript src=/plugins/lightgallery/js/lightgallery.js></script>
<script type=text/javascript src=/plugins/lightgallery/js/lg-thumbnail.js></script>
<script type=text/javascript src=/plugins/lightgallery/js/lg-video.js></script>
<script type=text/javascript src=/plugins/lightgallery/js/lg-zoom.js></script>
<script type=text/javascript src=/js/custom.js></script>
<script type=text/javascript src=/js/header_helpers.js></script>
<script>(function(e,t,n,s,o){e[s]=e[s]||[],e[s].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var a=t.getElementsByTagName(n)[0],i=t.createElement(n),r=s!="dataLayer"?"&l="+s:"";i.async=!0,i.src="https://www.googletagmanager.com/gtm.js?id="+o+r,a.parentNode.insertBefore(i,a)})(window,document,"script","dataLayer","GTM-T5X4T27")</script><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T5X4T27" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><script type=text/javascript>$(document).ready(function(){$("a").off("click").click(function(e){ga("send","event","a",e.type,$(this).attr("id"),1)}),$("[class *= trackClicks_]").off("click").click(function(e){var n=$(this).attr("class").split(/\s+/),t="";$.each(n,function(e,n){n.indexOf("trackClicks_")===0&&(t=n)}),ga("send","event","a",e.type,t,1)})})</script></head><body><header id=top class="header navbar-fixed-top"><div class=container><h1 class="logo pull-left"><a id=header-orangelogo href=/><img id=logo-image class=logo-image src=/images/orange_logo_hq.png alt=Logo></a></h1><nav id=main-nav class="main-nav navbar-right" role=navigation><div class=navbar-header><button class=navbar-toggle type=button data-toggle=collapse data-target=#navbar-collapse>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button></div><div class="navbar-collapse collapse" id=navbar-collapse><ul class="nav navbar-nav"><li class=nav-item><a id=header-screenshots-link href=/screenshots/>Screenshots</a></li><li class=nav-item><a id=header-screenshots-link href=/workflows/>Workflows</a></li><li class=nav-item><a id=header-screenshots-link href=/download/>Download</a></li><li class=nav-item><a id=header-screenshots-link href=/blog/>Blog</a></li><li class=nav-item><a id=header-screenshots-link href=/docs/>Docs</a></li><li class=nav-item><a id=header-screenshots-link href=/training/>Workshops</a></li><li class=nav-search-wrapper><div><a class="btn nav-btn-search btn-warning nav-btn fa fa-search nav-btn-desktop" id=search-btn-js role=button></a><a class="btn nav-btn-search btn-warning nav-btn fa fa-search nav-btn-mobile" role=button href="/search/?q="></a><input type=text class="header-search-input jsonly search-widget-workflow nav-item" id=search-header placeholder=Search tabindex=1 onkeydown=check_key_header(event) hidden autofocus></div></li><li><div class="donate-button transform_header donate_div"><a class="btn btn-warning nav-btn" id=header-donate-link role=button target=_blank href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=A76TAX87ZVR3J">Donate</a></div></li></ul></div></nav></div></header><div id=main><div class="container-fluid clear-top"><div id=overflow-container class=overflow-container><div id=loop-container class="offset-header container"><div class="blog-font-size post type-post status-publish format-standard category-standard category-travel full-without-featured odd excerpt-1 no-image"><div class="entry-meta remove-padding-l-r"><span>Categories:</span>
<span class=category><a href=/blog/fairness>fairness</a></span>
<span class=category><span>|</span>
<a href=/blog/equal-odds-postprocessing>equal odds postprocessing</a></span></div><div class='entry-header remove-padding-l-r'><h1 class=entry-title>Orange Fairness - Equal Odds Postprocessing</h1><span class=author-blog>By: Žan Mervič,
Sep 19, 2023</span></div><div class="entry-container remove-padding-l-r"><div class="entry-content md"><article><div id=blog_images_><p>In the <a href=/blog/2023/2023-09-19-fairness-adversarial-debiasing/>previous blog post</a>, we discussed the Adversarial Debiasing model, a bias-aware model. This blog post will discuss the Equal Odds Postprocessing widget, a bias-aware post-processor, which can be used with any model to mitigate bias in its predictions.</p><h3 id=equal-odds-postprocessing>Equal Odds Postprocessing:</h3><p>The <a href=https://arxiv.org/abs/1610.02413>Equal Odds Postprocessing</a> widget is a post-processing type of fairness mitigation algorithm for supervised learning. It modifies the predictions of any given classifier to meet certain fairness criteria, specifically focusing on &ldquo;Equalized Odds&rdquo; or more relaxed criteria like Equal Opportunity. Because it is a post-processing algorithm, it is versatile and can be used with most models, unlike some pre-processing or in-processing algorithms.</p><p>The Equalized Odds Postprocessing widget introduces a unique functionality in the Orange environment. It works similarly to other Orange widgets representing models, except it also expects a learner as an input.</p><p>It works by first fitting the learner to the training data, creating a model, and using it to get the predictions. It then uses these predictions to fit the Equalized Odds Postprocessing algorithm from the <a href=https://aif360.res.ibm.com/>AIF360</a> library, which creates a post-processor. This post-processor is then used to adjust the model&rsquo;s predictions on the test data. The result is a model that has been adjusted to meet the fairness criteria of Equalized Odds.</p><p>The Equalized Odds Postprocessing algorithm works by solving a linear program with some constraints and the following objective function:</p><p><code>c = [fpr_0 - tpr_0, tnr_0 - fnr_0, fpr_1 - tpr_1, tnr_1 - fnr_1]</code></p><p>Where <code>fpr</code>, <code>tpr</code>, <code>tnr</code>, and <code>fnr</code> are the false positive, true positive, true negative, and false negative rates for privileged (<code>0</code>) and unprivileged (<code>1</code>) groups.</p><p>The algorithm then finds the optimal solution to the linear program, which results in a set of probabilities with which to flip the model&rsquo;s predictions to equalize the odds of being correctly or incorrectly classified for both privileged and unprivileged groups:</p><ul><li><code>sp2p</code>: From positive to negative for the privileged group.</li><li><code>sn2p</code>: From negative to positive for the privileged group.</li><li><code>op2p</code>: From positive to negative for the unprivileged group.</li><li><code>on2p</code>: From negative to positive for the unprivileged group.</li></ul><h2 id=orange-use-case>Orange use case</h2><p>Now that we know how the Equal Odds Postprocessing widget works and how to use it let us look at a real-world example for a classification task.</p><p>For this example, we will use the <a href=http://archive.ics.uci.edu/dataset/144/statlog+german+credit+data>German credit dataset</a>, which we have used <a href=/blog/2023/2023-08-25-fairness-reweighing-preprocessor/>before</a>. The German Credit is a dataset related to bank loans. The main goal is to assess an individual&rsquo;s credit risk - whether a person is a good or bad credit risk. Unlike previously, we will not use the default fairness attributes that come with the dataset. Instead, we will use the age attribute, which we first discretize to two groups, younger and older than 26. We will set the older group as the privileged group.</p><p>We will train two Logistic Regression models, one with and one without the Equal Odds Postprocessing widget, and compare the predictions of these models.</p><a href=/blog_img/2023/2023-09-19-fairness-equal-odds-postprocessing-use-case.png class=blog-image_><img src=/blog_img/2023/2023-09-19-fairness-equal-odds-postprocessing-use-case.png class=window-screenshot></a>
<a href=/blog_img/2023/2023-09-19-fairness-equal-odds-postprocessing-scores.png class=blog-image_><img src=/blog_img/2023/2023-09-19-fairness-equal-odds-postprocessing-scores.png class=window-screenshot></a><p>The results show that the model using the Equal Odds Postprocessing widget has better fairness metrics than the model without it. Equal Odds Difference and Average Odds Difference are the main objectives of the Equal Odds Postprocessing algorithm, and we can see that they are much closer to zero when using the widget. We can also see that the Disparate Impact and Statistical Parity Difference metrics are much closer to their ideal values, which is a beneficial side effect rather than a direct result of the algorithm&rsquo;s optimization process and is not guaranteed to happen in all cases.</p><p>We can also see that the model&rsquo;s accuracy using the Equal Odds Postprocessing widget is slightly lower than without it. This is expected because the model is now not only trying to be accurate but also fair. This balance is a necessary trade-off we accept when we want to remove bias.</p><p>When using the Equal Odds Postprocessing, it is worth noting that the AUC value is not an accurate representation of the model&rsquo;s performance. This is because the Equal Odds Postprocessing algorithm changes only the predictions of the model, not the prediction probabilities. This means the AUC value would be calculated from the original model&rsquo;s prediction probabilities, not the adjusted ones. We have decided to alter the prediction probabilities when using the Equal Odds Postprocessing widget to 1 if the prediction is of the positive class and 0 otherwise. This is done to ensure that the AUC value is calculated from the adjusted predictions, which is a more accurate representation of the model&rsquo;s performance but still not a perfect one.</p><p>Next, let us look at the mosaic display widget. We will use it to show the True Positive Rate for each group and thus the Equal Opportunity Difference metric, which is the difference of the True Positive Rates between unprivileged and privileged groups. To do this, we first had to use the Select Rows widget to keep only the instances with a positive class because we are not interested in the True Negative Rate. This was the result:</p><a href=/blog_img/2023/2023-09-19-fairness-equal-odds-postprocessing-mosaic-bias.png class=blog-image_><img src=/blog_img/2023/2023-09-19-fairness-equal-odds-postprocessing-mosaic-bias.png class=window-screenshot></a>
<a href=/blog_img/2023/2023-09-19-fairness-equal-odds-postprocessing-mosaic-debias.png class=blog-image_><img src=/blog_img/2023/2023-09-19-fairness-equal-odds-postprocessing-mosaic-debias.png class=window-screenshot></a><p>In the visualizations, each column&rsquo;s red and blue parts represent the true positive and false negative rates, respectively, for each group. You can ignore the width of the columns as that represents the number of instances in each group, which is irrelevant to us.</p><p>In the first visualization, which represents predictions from the model without debiasing, we can see that the privileged group (>=26) has a higher True Positive Rate than the unprivileged group (&lt;26). This can be considered unfair towards the unprivileged group because it means a loan candidate from the unprivileged group is more likely to be falsely rejected, because of the higher false negative rate, than a loan candidate from the privileged group.</p><p>In the second visualization, representing predictions from the model with debiasing, we can see that the True Positive Rate for the privileged group has decreased and is now almost equal to the True Positive Rate for the unprivileged group. While this means the model is now less accurate for the privileged group, it is as accurate as it is for the unprivileged group, which could be considered a fairer outcome.</p></div></article></div></div></div></div></div><div id=disqus_thread></div><script>(function(){var e=document,t=e.createElement("script");t.src="https://orange-4.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div><script type=text/javascript>$(document).ready(function(){$("#blog_images_").lightGallery({thumbnail:!1,selector:"a:has(img)",width:"60%",mode:"lg-fade",counter:!1,download:!1,enableSwipe:!1,enableDrag:!1,speed:1,useLeft:!0,hideBarsDelay:1e3})})</script></div></div><footer class=footer><div class=container><div class=row><div class="col-md-4 col-sm-6 col-xs-12"><div class=row><div class="col-sm-4 sitemap-group"><ul class="links list-sitemap"><li><b><div class=sitemap-cat>Orange</div></b></li><li><a class=sitemap-sub href=/faq/>FAQ</a></li><li><a class=sitemap-sub href=/license/>License</a></li><li><a class=sitemap-sub href=/privacy/>Privacy</a></li><li><a class=sitemap-sub href=/citation/>Citation</a></li><li><a class=sitemap-sub href=/contact/>Contact</a></li></ul></div><div class="col-sm-4 sitemap-group"><ul class="links list-sitemap"><li><div class=sitemap-cat>Download</div></li><li><a class=sitemap-sub href=/download/#windows>Windows</a></li><li><a class=sitemap-sub href=/download/#macos>Mac OS</a></li></ul></div><div class="col-sm-4 sitemap-group"><ul class="links list-sitemap"><li><b><div class=sitemap-cat>Community</div></b></li><li><a class=sitemap-sub href=https://www.facebook.com/orangedatamining target=_blank>Facebook</a></li><li><a class=sitemap-sub href=https://www.youtube.com/channel/UClKKWBe2SCAEyv7ZNGhIe4g target=_blank>YouTube</a></li><li><a class=sitemap-sub href=https://twitter.com/orangedataminer target=_blank>Twitter</a></li><li><a class=sitemap-sub href=https://datascience.stackexchange.com/questions/tagged/orange target=_blank>Stack Exchange</a></li><li><a class=sitemap-sub href=https://discord.gg/FWrfeXV target=_blank>Discord</a></li></ul></div></div></div><div class="col-md-3 col-sm-6 col-xs-12"><div class=row><div class="col-sm-5 col-md-7 col-lg-6 sitemap-group docs-devs"><ul class="links list-sitemap"><li><div class=sitemap-cat>Documentation</div></li><li><a class=sitemap-sub href=/getting-started/>Get started</a></li><li><a class=sitemap-sub href=/widget-catalog/>Widgets</a></li><li><a class=sitemap-sub href=http://docs.biolab.si/3/data-mining-library/>Scripting</a></li></ul></div><div class="col-sm-3 sitemap-group"><ul class="links list-sitemap"><li><b><div class=sitemap-cat>Developers</div></b></li><li><a class=sitemap-sub target=_blank href=https://github.com/biolab/orange3>GitHub</a></li><li><a class=sitemap-sub target=_blank href=http://docs.biolab.si/3/development/>Getting Started</a></li></ul></div></div></div><div class="col-md-5 col-sm-12 col-xs-12 sitemap-group"><div class=latest-blog-posts><ul class="links list-sitemap" style=padding-bottom:10px><li><b><a class=sitemap-cat href=/blog/>Latest blog posts</a></b></li><li><div class=row><div class=col-md-2><a class=sitemap-sub>17 Oct</a></div><div class=col-md-10><a class=sitemap-sub style=color:#f79211 href=/blog/2023/2023-09-01-announcement-nomogram/>Fall Season Brings Fresh Content to the Introduction to Data Science Series</a></div></div></li><li><div class=row><div class=col-md-2><a class=sitemap-sub>19 Sep</a></div><div class=col-md-10><a class=sitemap-sub style=color:#f79211 href=/blog/2023/2023-09-19-fairness-hiding-protected-attribute/>Why Removing Features Isn't Enough</a></div></div></li><li><div class=row><div class=col-md-2><a class=sitemap-sub>19 Sep</a></div><div class=col-md-10><a class=sitemap-sub style=color:#f79211 href=/blog/2023/2023-09-19-fairness-reweighing-preprocessor/>Orange Fairness - Reweighing as a preprocessor</a></div></div></li></ul></div></div></div><div class="row footer-pad"><div class=col-xs-12><small class="copyright pull-left">Copyright © University of Ljubljana</small></div></div></div></footer></body></html>