<html><head><title>Orange Data Mining - Why Removing Features Isn't Enough</title><meta property="og:title" content="Why Removing Features Isn't Enough"><meta property="og:description" content="Find out why merely removing protected attributes will not fix bias. Features often correlate, letting models infer biases. Fairness algorithms are key for genuine bias mitigation."><meta property="og:image" content="/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-thumb.png"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Orange Data Mining Toolbox"><meta name=author content="Bioinformatics Laboratory, University of Ljubljana"><meta name=google-site-verification content="DS7GH5M7ABi78pIC2rMcTBFx-UeBFObXOeLvR7Ow3EQ"><link rel="shortcut icon" href=/images/favicon.ico><link href='https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic' rel=stylesheet type=text/css><link href='https://fonts.googleapis.com/css?family=Covered+By+Your+Grace' rel=stylesheet type=text/css><link rel=stylesheet href=/plugins/bootstrap/css/bootstrap.min.css><link rel=stylesheet href=/plugins/font-awesome/css/font-awesome.css><link rel=stylesheet href=/plugins/lightgallery/css/lightgallery.css><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css rel=stylesheet><link rel=stylesheet href=/scss/main.58e8531e166454b3665e4c7132aa2f1762a5569c179efa4bbf56b266ce93bfac.css><script id=dsq-count-scr src=//orange-4.disqus.com/count.js async></script><noscript><style>.jsonly{display:none!important}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-J6PJZF75EX"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-J6PJZF75EX",{anonymize_ip:!1})}</script><script type=text/javascript src=/plugins/jquery-1.10.2.min.js></script>
<script type=text/javascript src=/plugins/jquery.form.js></script>
<script type=text/javascript src=/plugins/bootstrap/js/bootstrap.min.js></script>
<script type=text/javascript src=/plugins/lightgallery/js/lightgallery.js></script>
<script type=text/javascript src=/plugins/lightgallery/js/lg-thumbnail.js></script>
<script type=text/javascript src=/plugins/lightgallery/js/lg-video.js></script>
<script type=text/javascript src=/plugins/lightgallery/js/lg-zoom.js></script>
<script type=text/javascript src=/js/custom.js></script>
<script type=text/javascript src=/js/header_helpers.js></script>
<script>(function(e,t,n,s,o){e[s]=e[s]||[],e[s].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var a=t.getElementsByTagName(n)[0],i=t.createElement(n),r=s!="dataLayer"?"&l="+s:"";i.async=!0,i.src="https://www.googletagmanager.com/gtm.js?id="+o+r,a.parentNode.insertBefore(i,a)})(window,document,"script","dataLayer","GTM-T5X4T27")</script><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T5X4T27" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><script type=text/javascript>$(document).ready(function(){$("a").off("click").click(function(e){ga("send","event","a",e.type,$(this).attr("id"),1)}),$("[class *= trackClicks_]").off("click").click(function(e){var n=$(this).attr("class").split(/\s+/),t="";$.each(n,function(e,n){n.indexOf("trackClicks_")===0&&(t=n)}),ga("send","event","a",e.type,t,1)})})</script></head><body><header id=top class="header navbar-fixed-top"><div class=container><h1 class="logo pull-left"><a id=header-orangelogo href=/><img id=logo-image class=logo-image src=/images/orange_logo_hq.png alt=Logo></a></h1><nav id=main-nav class="main-nav navbar-right" role=navigation><div class=navbar-header><button class=navbar-toggle type=button data-toggle=collapse data-target=#navbar-collapse>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button></div><div class="navbar-collapse collapse" id=navbar-collapse><ul class="nav navbar-nav"><li class=nav-item><a id=header-screenshots-link href=/screenshots/>Screenshots</a></li><li class=nav-item><a id=header-screenshots-link href=/workflows/>Workflows</a></li><li class=nav-item><a id=header-screenshots-link href=/download/>Download</a></li><li class=nav-item><a id=header-screenshots-link href=/blog/>Blog</a></li><li class=nav-item><a id=header-screenshots-link href=/docs/>Docs</a></li><li class=nav-item><a id=header-screenshots-link href=/training/>Workshops</a></li><li class=nav-search-wrapper><div><a class="btn nav-btn-search btn-warning nav-btn fa fa-search nav-btn-desktop" id=search-btn-js role=button></a><a class="btn nav-btn-search btn-warning nav-btn fa fa-search nav-btn-mobile" role=button href="/search/?q="></a><input type=text class="header-search-input jsonly search-widget-workflow nav-item" id=search-header placeholder=Search tabindex=1 onkeydown=check_key_header(event) hidden autofocus></div></li><li><div class="donate-button transform_header donate_div"><a class="btn btn-warning nav-btn" id=header-donate-link role=button target=_blank href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=A76TAX87ZVR3J">Donate</a></div></li></ul></div></nav></div></header><div id=main><div class="container-fluid clear-top"><div id=overflow-container class=overflow-container><div id=loop-container class="offset-header container"><div class="blog-font-size post type-post status-publish format-standard category-standard category-travel full-without-featured odd excerpt-1 no-image"><div class="entry-meta remove-padding-l-r"><span>Categories:</span>
<span class=category><a href=/blog/fairness>fairness</a></span></div><div class='entry-header remove-padding-l-r'><h1 class=entry-title>Why Removing Features Isn't Enough</h1><span class=author-blog>By: Žan Mervič,
Sep 19, 2023</span></div><div class="entry-container remove-padding-l-r"><div class="entry-content md"><article><div id=blog_images_><p>Previously, we introduced and explained different fairness algorithms that can be used to mitigate bias in a dataset or model predictions. Here, we will discuss a common misconception: removing the protected attribute from the dataset will remove bias. We show why this is not the case and why it is essential to use fairness algorithms.</p><h2 id=hiding-protected-attribute>Hiding Protected Attribute:</h2><p>Our setup is the following: we have two workflows, and both are using the adult data set. In the first workflow, we will train a logistic regression model using Reweighing as a preprocessor and a regular logistic regression model as a baseline on data that has not been modified. The second workflow uses the same dataset but with the protected attribute removed. We will then compare the predictions of the two workflows using a Box Plot.</p><a href=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-use-case-1.png class=blog-image_><img src=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-use-case-1.png class=window-screenshot></a>
<a href=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-use-case-2.png class=blog-image_><img src=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-use-case-2.png class=window-screenshot></a><p>The two workflows are very similar, the only difference being the extra learner used in the first workflow, the reweighted learner, and two Select Columns widgets used in the second workflow. The first Select Columns widget is used to remove the protected attribute from the data, and the second one is used to add it back after the predictions are made so that we can compare the predictions of the two workflows using a Box Plot widget.</p><p>In this example, we will not be able to use the scores to compare the fairness metrics of the models because we could not calculate the fairness metrics for the workflow with the hidden protected attribute. This is because the protected attribute is required to calculate the fairness metrics. Saying that we can still compare the accuracy scores of the models. Here are the scores for the reweighted model, the baseline model, and the model learning on altered data:</p><a href=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-scores.png class=blog-image_><img src=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-scores.png class=window-screenshot></a><p>The baseline model and the model learning on altered data have very similar accuracy scores, while the reweighted model has a slight dip in accuracy.</p><p>Instead of using the scores to compare the models, we will visualize the fairness Disparate Impact and Statistical Parity Difference fairness metrics using the Box Plot widget, just like we did in many previous blogs. Here we will show three different box plots, the first one will be from the reweighted model, the second one from the baseline, and the third from the model learning on data with the protected attribute removed:</p><a href=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-box-plot.png class=blog-image_><img src=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-box-plot.png class=window-screenshot></a><p>The box plots show that the baseline model results are very similar to the model learning on data with the protected attribute removed. In contrast, the reweighted model results are very different. The ratio of favorable prediction is much more similar when using debiasing compared to the baseline model and the model learning on data with the protected attribute removed.</p><p>A similar observation can be made for the Equalized Odds Difference and Average Odds Difference fairness metrics. Using a similar setup as in the <a href=/blog/2023/2023-09-19-fairness-equal-odds-postprocessing/>previous blog post</a>, we visualized the True Positive Rate for each group using the mosaic display widget. We trained one model using the Equalized Odds Postprocessing widget and one on data with the protected attribute &ldquo;age&rdquo; hidden. Here are the results:</p><a href=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-mosaic.png class=blog-image_><img src=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-mosaic.png class=window-screenshot></a><p>In the visualizations, the red part of each column represents the true positive rate for each group; you can ignore the width of the columns as that represents the number of instances in each group, which is irrelevant to us. We can see that the difference in True Positive Rate between the two groups is much smaller when using the Equal Odds Postprocessing widget.</p><h2 id=why-and-how>Why and how?</h2><p>If we removed the protected attribute from the dataset on which we train and test the model, how is it that the predictions are still biased towards one of the groups?</p><p>The answer is that features in a dataset are often correlated. This means that even if we remove the protected attribute, other features can still be used to infer the protected attribute. For example, suppose the protected attribute is race, and we have a feature like zip code in the data. Since certain races might be predominant in particular zip codes, the model may still indirectly learn the bias. We can test this correlation by predicting the protected attribute from the other features. If we can predict the protected attribute with high accuracy, we know that the other features are correlated with the protected attribute. Here is an example of such a workflow:</p><a href=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-sex.png class=blog-image_><img src=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-sex.png class=window-screenshot></a><p>In this workflow, we set the &ldquo;sex&rdquo; attribute as the target variable and use a Logistic Regression model to try and predict it.</p><a href=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-sex-scores.png class=blog-image_><img src=/blog_img/2023/2023-09-19-fairness-hiding-protected-attribute-sex-scores.png class=window-screenshot></a><p>We can see that the model has a very high accuracy score, which means that the other features in the dataset are correlated with the protected attribute. This means that even if we remove the protected attribute from the dataset, the model can still infer it from the other features. This is why it is crucial to use fairness algorithms instead of simply removing the protected attribute.</p></div></article></div></div></div></div></div><div id=disqus_thread></div><script>(function(){var e=document,t=e.createElement("script");t.src="https://orange-4.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div><script type=text/javascript>$(document).ready(function(){$("#blog_images_").lightGallery({thumbnail:!1,selector:"a:has(img)",width:"60%",mode:"lg-fade",counter:!1,download:!1,enableSwipe:!1,enableDrag:!1,speed:1,useLeft:!0,hideBarsDelay:1e3})})</script></div></div><footer class=footer><div class=container><div class=row><div class="col-md-4 col-sm-6 col-xs-12"><div class=row><div class="col-sm-4 sitemap-group"><ul class="links list-sitemap"><li><b><div class=sitemap-cat>Orange</div></b></li><li><a class=sitemap-sub href=/faq/>FAQ</a></li><li><a class=sitemap-sub href=/license/>License</a></li><li><a class=sitemap-sub href=/privacy/>Privacy</a></li><li><a class=sitemap-sub href=/citation/>Citation</a></li><li><a class=sitemap-sub href=/contact/>Contact</a></li></ul></div><div class="col-sm-4 sitemap-group"><ul class="links list-sitemap"><li><div class=sitemap-cat>Download</div></li><li><a class=sitemap-sub href=/download/#windows>Windows</a></li><li><a class=sitemap-sub href=/download/#macos>Mac OS</a></li></ul></div><div class="col-sm-4 sitemap-group"><ul class="links list-sitemap"><li><b><div class=sitemap-cat>Community</div></b></li><li><a class=sitemap-sub href=https://www.facebook.com/orangedatamining target=_blank>Facebook</a></li><li><a class=sitemap-sub href=https://www.youtube.com/channel/UClKKWBe2SCAEyv7ZNGhIe4g target=_blank>YouTube</a></li><li><a class=sitemap-sub href=https://twitter.com/orangedataminer target=_blank>Twitter</a></li><li><a class=sitemap-sub href=https://datascience.stackexchange.com/questions/tagged/orange target=_blank>Stack Exchange</a></li><li><a class=sitemap-sub href=https://discord.gg/FWrfeXV target=_blank>Discord</a></li></ul></div></div></div><div class="col-md-3 col-sm-6 col-xs-12"><div class=row><div class="col-sm-5 col-md-7 col-lg-6 sitemap-group docs-devs"><ul class="links list-sitemap"><li><div class=sitemap-cat>Documentation</div></li><li><a class=sitemap-sub href=/getting-started/>Get started</a></li><li><a class=sitemap-sub href=/widget-catalog/>Widgets</a></li><li><a class=sitemap-sub href=http://docs.biolab.si/3/data-mining-library/>Scripting</a></li></ul></div><div class="col-sm-3 sitemap-group"><ul class="links list-sitemap"><li><b><div class=sitemap-cat>Developers</div></b></li><li><a class=sitemap-sub target=_blank href=https://github.com/biolab/orange3>GitHub</a></li><li><a class=sitemap-sub target=_blank href=http://docs.biolab.si/3/development/>Getting Started</a></li></ul></div></div></div><div class="col-md-5 col-sm-12 col-xs-12 sitemap-group"><div class=latest-blog-posts><ul class="links list-sitemap" style=padding-bottom:10px><li><b><a class=sitemap-cat href=/blog/>Latest blog posts</a></b></li><li><div class=row><div class=col-md-2><a class=sitemap-sub>24 Oct</a></div><div class=col-md-10><a class=sitemap-sub style=color:#f79211 href=/blog/2023/2023-10-24-dask-all-folks/>Dask all Folks: preparing large datasets</a></div></div></li><li><div class=row><div class=col-md-2><a class=sitemap-sub>20 Oct</a></div><div class=col-md-10><a class=sitemap-sub style=color:#f79211 href=/blog/2023/2023-10-20-porto-conference/>Recap of 26th International Conference on Discovery Science</a></div></div></li><li><div class=row><div class=col-md-2><a class=sitemap-sub>17 Oct</a></div><div class=col-md-10><a class=sitemap-sub style=color:#f79211 href=/blog/2023/2023-09-01-announcement-nomogram/>Fall Season Brings Fresh Content to the Introduction to Data Science Series</a></div></div></li></ul></div></div></div><div class="row footer-pad"><div class=col-xs-12><small class="copyright pull-left">Copyright © University of Ljubljana</small></div></div></div></footer></body></html>