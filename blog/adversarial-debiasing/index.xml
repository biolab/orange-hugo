<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>adversarial debiasing on Orange</title><link>/blog/adversarial-debiasing/</link><description>Recent content in adversarial debiasing on Orange</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 19 Sep 2023 00:00:00 +0000</lastBuildDate><atom:link href="/blog/adversarial-debiasing/index.xml" rel="self" type="application/rss+xml"/><item><title>Orange Fairness - Adversarial Debiasing</title><link>/blog/2023/2023-09-19-fairness-adversarial-debiasing/</link><pubDate>Tue, 19 Sep 2023 00:00:00 +0000</pubDate><guid>/blog/2023/2023-09-19-fairness-adversarial-debiasing/</guid><description>In the previous blog post, we talked about how to use the Reweighing widget as a preprocessor for a model. This blog post will discuss the Adversarial Debiasing model, a bias-aware model. We will also show how to use it in Orange.
Adversarial Debiasing: Adversarial Debiasing is an in-processing type of fairness mitigation algorithm. It is a technique that uses adversarial training to mitigate bias. It involves simultaneous training of a predictor and a discriminator.</description></item></channel></rss>