<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>equal odds postprocessing on Orange</title><link>/blog/equal-odds-postprocessing/</link><description>Recent content in equal odds postprocessing on Orange</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 19 Sep 2023 00:00:00 +0000</lastBuildDate><atom:link href="/blog/equal-odds-postprocessing/index.xml" rel="self" type="application/rss+xml"/><item><title>Orange Fairness - Equal Odds Postprocessing</title><link>/blog/2023/2023-09-19-fairness-equal-odds-postprocessing/</link><pubDate>Tue, 19 Sep 2023 00:00:00 +0000</pubDate><guid>/blog/2023/2023-09-19-fairness-equal-odds-postprocessing/</guid><description>In the previous blog post, we discussed the Adversarial Debiasing model, a bias-aware model. This blog post will discuss the Equal Odds Postprocessing widget, a bias-aware post-processor, which can be used with any model to mitigate bias in its predictions.
Equal Odds Postprocessing: The Equal Odds Postprocessing widget is a post-processing type of fairness mitigation algorithm for supervised learning. It modifies the predictions of any given classifier to meet certain fairness criteria, specifically focusing on &amp;ldquo;Equalized Odds&amp;rdquo; or more relaxed criteria like Equal Opportunity.</description></item></channel></rss>