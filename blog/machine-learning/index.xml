<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine learning on Orange</title>
    <link>/blog/machine-learning/</link>
    <description>Recent content in machine learning on Orange</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Mar 2021 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/blog/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Hands-On Training About Overfitting</title>
      <link>/blog/2021/2021-03-05-overfitting-course/</link>
      <pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/2021/2021-03-05-overfitting-course/</guid>
      <description>PLOS Computation Biology has just published our paper on training about overfitting:
 Dem≈°ar J, Zupan B (2021) Hands-on training about overfitting. PLoS Comput Biol 17(3): e1008671.  Machine learning has recently propelled approaches for the analysis of data, but &amp;ldquo;for the uninitiated, the technology poses significant difficulties&amp;rdquo; (Deep learning for biology, Nature, Feb 22, 2018). One of the hard concepts for starters in machine learning is overfitting. Overfitting can lead to models that include patterns that do not generalize well and could be meaningless.</description>
    </item>
    
  </channel>
</rss>